{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5520,
     "status": "ok",
     "timestamp": 1708824225737,
     "user": {
      "displayName": "Dario Perla",
      "userId": "14261311295065514135"
     },
     "user_tz": 180
    },
    "id": "uEqkB-nejnvU",
    "outputId": "e1a2070c-32f6-4482-8689-64da0148a3eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: not using Google CoLab\n",
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "try:\n",
    "    import google.colab\n",
    "    COLAB = True\n",
    "    print(\"Note: using Google CoLab\")\n",
    "except:\n",
    "    print(\"Note: not using Google CoLab\")\n",
    "    COLAB = False\n",
    "\n",
    "# Make use of a GPU or MPS (Apple) if one is available.  (see module 3.2)\n",
    "import torch\n",
    "has_mps = torch.backends.mps.is_built()\n",
    "device = \"mps\" if has_mps else \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1130,
     "status": "ok",
     "timestamp": 1708824226864,
     "user": {
      "displayName": "Dario Perla",
      "userId": "14261311295065514135"
     },
     "user_tz": 180
    },
    "id": "Lgjj4tCfkRfY",
    "outputId": "28a58b13-5922-4eda-87d2-abb20f606fda"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DMZServiciosN4_Web_U_EX240225.log\n",
      "['date', 'time', 's-computername', 's-ip', 'cs-method', 'cs-uri-stem', 'cs-uri-query', 's-port', 'cs-username', 'c-ip', 'cs(User-Agent)', 'cs(Referer)', 'cs-host', 'sc-status', 'sc-substatus', 'sc-win32-status', 'sc-bytes', 'cs-bytes', 'time-taken']\n",
      "Read 232076 rows.\n",
      "            time cs-method                cs-uri-stem cs-username  \\\n",
      "0       00:00:00      POST       /LuciaWS/awsdua.aspx        0642   \n",
      "1       00:00:00       GET  /luciaws/axmovstkxml.aspx     TRN0038   \n",
      "...          ...       ...                        ...         ...   \n",
      "232074  23:59:58      POST       /LuciaWS/awsdua.aspx        0642   \n",
      "232075  23:59:59      POST  /LuciaWsPr/awsprcrpt.aspx     OTR4085   \n",
      "\n",
      "                  c-ip                   cs-host  sc-status  sc-bytes  \\\n",
      "0        100.42.52.211  servicios.aduanas.gub.uy        200      3397   \n",
      "1       200.58.138.180  servicios.aduanas.gub.uy        200      1813   \n",
      "...                ...                       ...        ...       ...   \n",
      "232074   100.42.52.211  servicios.aduanas.gub.uy        200      3253   \n",
      "232075    200.40.42.95  servicios.aduanas.gub.uy        200      1093   \n",
      "\n",
      "        cs-bytes  time-taken  \n",
      "0            702         298  \n",
      "1            800         189  \n",
      "...          ...         ...  \n",
      "232074       702         281  \n",
      "232075      1167         112  \n",
      "\n",
      "[232076 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import urllib.request\n",
    "import os\n",
    "\n",
    "# Set Pandas display options\n",
    "pd.set_option('display.max_columns', 6)\n",
    "pd.set_option('display.max_rows', 5)\n",
    "\n",
    "# Download the file using urllib\n",
    "url = 'https://github.com/jeffheaton/jheaton-ds2/raw/main/kdd-with-columns.csv'\n",
    "filename = 'DMZServiciosN4_Web_U_EX240225.log'\n",
    "\n",
    "if not os.path.isfile(filename):\n",
    "    try:\n",
    "        urllib.request.urlretrieve(url, filename)\n",
    "    except:\n",
    "        print('Error downloading')\n",
    "        raise\n",
    "\n",
    "print(filename)\n",
    "# Cargo titulos de columnas\n",
    "with open(filename, 'r') as file:\n",
    "    for line in file:\n",
    "        if line.startswith('#Fields:'):\n",
    "            # Eliminar el prefijo y el salto de línea, luego dividir por espacio\n",
    "            columnanombre = line.replace('#Fields: ', '').strip().split()\n",
    "            break\n",
    "\n",
    "print(columnanombre)\n",
    "\n",
    "\n",
    "# Se cargan los datos con las columnas a utilizar\n",
    "cols_to_use = ['time', 'cs-method', 'cs-uri-stem', 'cs-username','c-ip','cs-host','sc-status'\n",
    "                                                         ,'sc-bytes','cs-bytes','time-taken']\n",
    "\n",
    "df = pd.read_csv(filename, sep=' ', names=columnanombre, comment='#',usecols=cols_to_use)\n",
    "print(\"Read {} rows.\".format(len(df)))\n",
    "\n",
    "# Display 5 rows\n",
    "pd.set_option('display.max_columns', 15)\n",
    "pd.set_option('display.max_rows', 5)\n",
    "              \n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Comienza el trabajo con los datos para CATEGORIZAR LOS CAMPOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Campo sc-status \n",
    "# elimanmos todos los errores del aplicativo y solo nos quedamos con los 200 (ok)\n",
    "#   Al eliminar esta columna evitamos tener aplitivos que no existen o sin usuario (401 y 404) ademas de erres del servidor 500.\n",
    "df = df[df['sc-status'] == 200]\n",
    "\n",
    "## eliminamos la columna sc-status\n",
    "df = df.drop('sc-status', axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1708824226865,
     "user": {
      "displayName": "Dario Perla",
      "userId": "14261311295065514135"
     },
     "user_tz": 180
    },
    "id": "gdWx8W0sk0IU",
    "outputId": "ac64f36b-5d25-4ba1-de2f-e9338c8ff852"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        aWSPrcRpt.aspx  aWSPrcRptV2.aspx  aavisoretiropreembarquead.aspx  \\\n",
      "0                False             False                           False   \n",
      "1                False             False                           False   \n",
      "...                ...               ...                             ...   \n",
      "232074           False             False                           False   \n",
      "232075           False             False                           False   \n",
      "\n",
      "        afxmldua.aspx  afxmlhis.aspx  aingresoaterminalad.aspx  \\\n",
      "0               False          False                     False   \n",
      "1               False          False                     False   \n",
      "...               ...            ...                       ...   \n",
      "232074          False          False                     False   \n",
      "232075          False          False                     False   \n",
      "\n",
      "        atradwsds.aspx  ...  awsdua.aspx  awsestsrvprcele.aspx  \\\n",
      "0                False  ...         True                 False   \n",
      "1                False  ...        False                 False   \n",
      "...                ...  ...          ...                   ...   \n",
      "232074           False  ...         True                 False   \n",
      "232075           False  ...        False                 False   \n",
      "\n",
      "        awsmovimientosmigratorios.aspx  awsmovstock.aspx  awsprcrpt.aspx  \\\n",
      "0                                False             False           False   \n",
      "1                                False             False           False   \n",
      "...                                ...               ...             ...   \n",
      "232074                           False             False           False   \n",
      "232075                           False             False            True   \n",
      "\n",
      "        axmovstkxml.aspx  otros  \n",
      "0                  False  False  \n",
      "1                   True  False  \n",
      "...                  ...    ...  \n",
      "232074             False  False  \n",
      "232075             False  False  \n",
      "\n",
      "[170026 rows x 20 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "### Campo cs-uri-stem o campo del aplicativo a invocar\n",
    "\n",
    "\n",
    "# PARA NORMALIZAR - Reemplazar 'dna\\' o 'DNA\\' al comienzo de 'cs-username' por una cadena vacía, insensible a mayúsculas/minúsculas \n",
    "df['cs-uri-stem'] = df['cs-uri-stem'].str.split('/').str[-1]\n",
    "                                                    \n",
    "\n",
    "# Agrupar , contar, ordenar y obtener los 19 mas frecuentes  y el 20 va a ser el resto 'otros'\n",
    "top_20_csuristem = df.groupby('cs-uri-stem')['cs-uri-stem'].count().sort_values(ascending=False).head(19).index.tolist()\n",
    "\n",
    "\n",
    "# Crear una nueva columna que categoriza 'cs-username'\n",
    "df['cs-uri-stem-cat'] = df['cs-uri-stem'].apply(lambda x: x if x in top_20_csuristem else 'otros')\n",
    "\n",
    "# Convertir la nueva columna categorizada a variables one-hot-encoding (vector de 20  bits donde solo esta activo el que corresponde) \n",
    "csuristem_dummies = pd.get_dummies(df['cs-uri-stem-cat'])\n",
    "\n",
    "print(csuristem_dummies)\n",
    "\n",
    "# Guardar la lista en un archivo de texto  las categorias que seran necesarias para evaluar el trafico neuvo con la misma categorizacion\n",
    "\n",
    "with open('lista_categorias_csuristem.csv', 'w') as archivo:\n",
    "    for elemento in top_20_csuristem:\n",
    "        archivo.write(\"%s\\n\" % elemento)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1708824226865,
     "user": {
      "displayName": "Dario Perla",
      "userId": "14261311295065514135"
     },
     "user_tz": 180
    },
    "id": "gdWx8W0sk0IU",
    "outputId": "ac64f36b-5d25-4ba1-de2f-e9338c8ff852"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        23a6  6a9y19a23   9a19\n",
      "0       True      False  False\n",
      "1       True      False  False\n",
      "...      ...        ...    ...\n",
      "232074  True      False  False\n",
      "232075  True      False  False\n",
      "\n",
      "[170026 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "### Campo time\n",
    "## Realizaremos una particion del tieme en 4 categorias . de 23 a 6 (hora de alto hacking), 6 a 9 y 19 a 23 y el central de 9 a 19\n",
    "# Para ello se parte de un vector binario one-hot-encoding de 3 elementos (23 a 6 = 100 , de 9 a 19 = 010 y resto = 001\n",
    "\n",
    "# Convertir la columna 'time' a datetime\n",
    "# Dividir la cadena por ':' y quedarse con la parte antes del primer ':'\n",
    "def categorizar_por_hora(time):\n",
    "    # Primero, dividimos el string para extraer la hora\n",
    "    hora = int(time.split(':')[0])  # Convertimos a entero el primer elemento luego de hacer split por ':'\n",
    "    \n",
    "    # Ahora, categorizamos según los rangos definidos\n",
    "    if (6 <= hora < 9) or (19 <= hora < 23):\n",
    "        return '6a9y19a23'\n",
    "    elif 9 <= hora < 19:\n",
    "        return '9a19'\n",
    "    elif hora >= 23 or hora < 6:\n",
    "        return '23a6'\n",
    "    else:\n",
    "        return 'Otro' \n",
    "\n",
    "# Aplicar la función para categorizar\n",
    "df['time-cat'] = df['time'].apply(categorizar_por_hora)\n",
    "\n",
    "              \n",
    "\n",
    "# Agrupar , contar, ordenar y obtener los 19 mas frecuentes  y el 20 va a ser el resto 'otros'\n",
    "lista_timeCategoria = ['6a9y19a23','9a19','23a6']\n",
    "\n",
    "\n",
    "\n",
    "# Convertir la nueva columna categorizada a variables one-hot-encoding (vector de 20  bits donde solo esta activo el que corresponde) \n",
    "time_dummies = pd.get_dummies(df['time-cat'])\n",
    "\n",
    "print(time_dummies)\n",
    "\n",
    "# Guardar la lista en un archivo de texto  las categorias que seran necesarias para evaluar el trafico neuvo con la misma categorizacion\n",
    "\n",
    "with open('lista_categorias_time.csv', 'w') as archivo:\n",
    "    for elemento in lista_timeCategoria:\n",
    "        archivo.write(\"%s\\n\" % elemento)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1708824226865,
     "user": {
      "displayName": "Dario Perla",
      "userId": "14261311295065514135"
     },
     "user_tz": 180
    },
    "id": "gdWx8W0sk0IU",
    "outputId": "ac64f36b-5d25-4ba1-de2f-e9338c8ff852"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         0063   0642   3001   3004   6084  ANPWS  DNMDNA  ...  bullmon  \\\n",
      "0       False   True  False  False  False  False   False  ...    False   \n",
      "1       False  False  False  False  False  False   False  ...    False   \n",
      "...       ...    ...    ...    ...    ...    ...     ...  ...      ...   \n",
      "232074  False   True  False  False  False  False   False  ...    False   \n",
      "232075  False  False  False  False  False  False   False  ...    False   \n",
      "\n",
      "        otr0624  otr0893  otr5690  otr9981  otros  trn0038  \n",
      "0         False    False    False    False  False    False  \n",
      "1         False    False    False    False   True    False  \n",
      "...         ...      ...      ...      ...    ...      ...  \n",
      "232074    False    False    False    False  False    False  \n",
      "232075    False    False    False    False  False    False  \n",
      "\n",
      "[170026 rows x 20 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "### Campo cs-username\n",
    "\n",
    "\n",
    "# PARA NORMALIZAR - Reemplazar 'dna\\' o 'DNA\\' al comienzo de 'cs-username' por una cadena vacía, insensible a mayúsculas/minúsculas \n",
    "df['cs-username'] = df['cs-username'].str.replace('^(?i)dna\\\\\\\\', '', regex=True)\n",
    "\n",
    "# Agrupar por 'cs-username', contar, ordenar y obtener los 19 mas frecuentes  y el 20 va a ser el resto 'otros'\n",
    "top_20_usernames = df.groupby('cs-username')['cs-username'].count().sort_values(ascending=False).head(19).index.tolist()\n",
    "\n",
    "\n",
    "# Crear una nueva columna que categoriza 'cs-username'\n",
    "df['cs-username-cat'] = df['cs-username'].apply(lambda x: x if x in top_20_usernames else 'otros')\n",
    "\n",
    "# Convertir la nueva columna categorizada a variables one-hot-encoding (vector de 20  bits donde solo esta activo el que corresponde al usuario) \n",
    "username_dummies = pd.get_dummies(df['cs-username-cat'])\n",
    "\n",
    "print(username_dummies)\n",
    "\n",
    "# Guardar la lista en un archivo de texto  las categorias que seran necesarias para evaluar el trafico neuvo con la misma categorizacion\n",
    "\n",
    "with open('lista_categorias_csusername.csv', 'w') as archivo:\n",
    "    for elemento in top_20_usernames:\n",
    "        archivo.write(\"%s\\n\" % elemento)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          GET   POST  otros\n",
      "0       False   True  False\n",
      "1        True  False  False\n",
      "...       ...    ...    ...\n",
      "232074  False   True  False\n",
      "232075  False   True  False\n",
      "\n",
      "[170026 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "### Campo cs-method\n",
    "\n",
    "\n",
    "\n",
    "# PARA NORMALIZAR - crearemos un vector de 3 bit dodne (100 = GET; 010 = Put ; 001 = Otro\n",
    "categoria_csmethod = ['GET','POST','OTROS']\n",
    "\n",
    "# Crear una nueva columna que categoriza 'cs-username'\n",
    "df['cs-method-cat'] = df['cs-method'].apply(lambda x: x if x in categoria_csmethod else 'otros')\n",
    "\n",
    "# Convertir la nueva columna categorizada a variables one-hot-encoding (vector de 20  bits donde solo esta activo el que corresponde al usuario) \n",
    "method_dummies = pd.get_dummies(df['cs-method-cat'])\n",
    "\n",
    "print(method_dummies)\n",
    "\n",
    "# Guardar la lista en un archivo de texto  las categorias que seran necesarias para evaluar el trafico neuvo con la misma categorizacion\n",
    "\n",
    "with open('lista_categorias_csmethod.csv', 'w') as archivo:\n",
    "    for elemento in categoria_csmethod:\n",
    "        archivo.write(\"%s\\n\" % elemento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número estimado de clusters: 51\n",
      "            time cs-method       cs-uri-stem cs-username            c-ip  \\\n",
      "0       00:00:00      POST       awsdua.aspx        0642   100.42.52.211   \n",
      "1       00:00:00       GET  axmovstkxml.aspx     TRN0038  200.58.138.180   \n",
      "...          ...       ...               ...         ...             ...   \n",
      "232074  23:59:58      POST       awsdua.aspx        0642   100.42.52.211   \n",
      "232075  23:59:59      POST    awsprcrpt.aspx     OTR4085    200.40.42.95   \n",
      "\n",
      "                         cs-host  sc-bytes  ...  cs-method-cat  \\\n",
      "0       servicios.aduanas.gub.uy      3397  ...           POST   \n",
      "1       servicios.aduanas.gub.uy      1813  ...            GET   \n",
      "...                          ...       ...  ...            ...   \n",
      "232074  servicios.aduanas.gub.uy      3253  ...           POST   \n",
      "232075  servicios.aduanas.gub.uy      1093  ...           POST   \n",
      "\n",
      "                   ip_split octet1 octet2 octet3 octet4 cluster  \n",
      "0        [100, 42, 52, 211]    100     42     52    211       0  \n",
      "1       [200, 58, 138, 180]    200     58    138    180       1  \n",
      "...                     ...    ...    ...    ...    ...     ...  \n",
      "232074   [100, 42, 52, 211]    100     42     52    211       0  \n",
      "232075    [200, 40, 42, 95]    200     40     42     95       7  \n",
      "\n",
      "[170026 rows x 19 columns]\n"
     ]
    }
   ],
   "source": [
    "### Campo cs-ip y vencindad\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Suponiendo que df es tu DataFrame con una columna 'ip_address'\n",
    "df['ip_split'] = df['c-ip'].str.split('.')\n",
    "df[['octet1', 'octet2', 'octet3', 'octet4']] = pd.DataFrame(df['ip_split'].tolist(), index=df.index).astype(int)\n",
    "\n",
    "# Ahora df tiene cuatro columnas nuevas: 'octet1', 'octet2', 'octet3', 'octet4'\n",
    "\n",
    "# Convertir las columnas de octetos a una matriz numérica y escalar los datos\n",
    "X = StandardScaler().fit_transform(df[['octet1', 'octet2', 'octet3', 'octet4']])\n",
    "\n",
    "# Aplicar DBSCAN\n",
    "# eps es la distancia máxima entre dos muestras para que una sea considerada en la vecindad de la otra\n",
    "# min_samples es el número de muestras en una vecindad para que un punto sea considerado un punto central\n",
    "db = DBSCAN(eps=0.5, min_samples=5).fit(X)\n",
    "\n",
    "# Las etiquetas de los clusters\n",
    "labels = db.labels_\n",
    "\n",
    "# Agregar las etiquetas al DataFrame original\n",
    "df['cluster'] = labels\n",
    "\n",
    "# Cantidad de clusters en las etiquetas, ignorando el ruido si es presente\n",
    "n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "\n",
    "print(f'Número estimado de clusters: {n_clusters_}')\n",
    "print(df)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qhXiGf_qlFuW"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def encode_numeric_zscore(df, name):\n",
    "    \"\"\"\n",
    "    Apply z-score normalization to a specified numeric column.\n",
    "\n",
    "    Parameters:\n",
    "    df (DataFrame): The pandas DataFrame containing the column.\n",
    "    name (str): The name of the column to normalize.\n",
    "    \"\"\"\n",
    "    mean = df[name].mean()\n",
    "    sd = df[name].std()\n",
    "    df[name] = (df[name] - mean) / sd\n",
    "\n",
    "def encode_text_dummy(df, name):\n",
    "    \"\"\"\n",
    "    Convert a categorical column to dummy variables.\n",
    "\n",
    "    Parameters:\n",
    "    df (DataFrame): The pandas DataFrame containing the column.\n",
    "    name (str): The name of the categorical column.\n",
    "    \"\"\"\n",
    "    dummies = pd.get_dummies(df[name], prefix=name, dtype=float)\n",
    "    df = pd.concat([df, dummies], axis=1)\n",
    "    df.drop(name, axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "def process_dataframe(df):\n",
    "    \"\"\"\n",
    "    Process a DataFrame by encoding its features.\n",
    "\n",
    "    Parameters:\n",
    "    df (DataFrame): The pandas DataFrame to process.\n",
    "    \"\"\"\n",
    "    for name in df.columns:\n",
    "        if name == 'checkpoint.rule_action':\n",
    "            continue\n",
    "        #elif df[name].dtype == bool:\n",
    "        #    print(\"**\", name)\n",
    "        #    df[name] = df[name].astype(float)\n",
    "    # \"\"\"    elif name in ['destination.port', 'source.port'\n",
    "        # , '@timestamp', 'logged_in',, 'service'\n",
    "             #         'source.ip', 'destination.ip'\n",
    "            #          ]:      encode_numeric_zscore(df, name) \"\"\"\n",
    "        else:\n",
    "            df = encode_text_dummy(df, name)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 417,
     "status": "ok",
     "timestamp": 1708824233482,
     "user": {
      "displayName": "Dario Perla",
      "userId": "14261311295065514135"
     },
     "user_tz": 180
    },
    "id": "h41ItP-1qF1w",
    "outputId": "49596bf5-2e4f-4263-a2c6-9aca23cc4051"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     event.created        source.ip source.port  \\\n",
      "17747  Feb 21, 2024 @ 21:20:06.263  192.168.250.216      22,584   \n",
      "8445   Feb 21, 2024 @ 21:24:04.419   200.40.211.251      50,859   \n",
      "...                            ...              ...         ...   \n",
      "3441   Feb 21, 2024 @ 21:26:15.271    179.27.47.201      29,628   \n",
      "18653  Feb 21, 2024 @ 21:19:41.420    179.27.96.252      58,266   \n",
      "\n",
      "        destination.ip destination.port source.geo.country_name  \\\n",
      "17747          8.8.8.8               53                       -   \n",
      "8445   192.168.245.254           18,234                 Uruguay   \n",
      "...                ...              ...                     ...   \n",
      "3441    200.40.211.236              443                 Uruguay   \n",
      "18653   200.40.211.236              443                 Uruguay   \n",
      "\n",
      "                         source.as.organization.name  \\\n",
      "17747                                              -   \n",
      "8445   Administracion Nacional de Telecomunicaciones   \n",
      "...                                              ...   \n",
      "3441   Administracion Nacional de Telecomunicaciones   \n",
      "18653  Administracion Nacional de Telecomunicaciones   \n",
      "\n",
      "      destination.geo.country_name network.application destination.nat.ip  \\\n",
      "17747                United States          domain-udp                  -   \n",
      "8445                             -         tunnel_test                  -   \n",
      "...                            ...                 ...                ...   \n",
      "3441                       Uruguay               https                  -   \n",
      "18653                      Uruguay               https                  -   \n",
      "\n",
      "                event.type network.transport checkpoint.rule_action  \\\n",
      "17747  allowed, connection               udp                 Accept   \n",
      "8445   allowed, connection               udp                 Accept   \n",
      "...                    ...               ...                    ...   \n",
      "3441   allowed, connection               tcp                 Accept   \n",
      "18653  allowed, connection               tcp                 Accept   \n",
      "\n",
      "      network.direction  \n",
      "17747           inbound  \n",
      "8445           outbound  \n",
      "...                 ...  \n",
      "3441            inbound  \n",
      "18653           inbound  \n",
      "\n",
      "[16328 rows x 14 columns]\n",
      "                     event.created        source.ip source.port  \\\n",
      "17747  Feb 21, 2024 @ 21:20:06.263  192.168.250.216      22,584   \n",
      "8445   Feb 21, 2024 @ 21:24:04.419   200.40.211.251      50,859   \n",
      "20364  Feb 21, 2024 @ 21:19:44.405   185.224.128.31      57,447   \n",
      "18416  Feb 21, 2024 @ 21:19:50.359   167.60.236.199      59,405   \n",
      "9619   Feb 21, 2024 @ 21:23:36.482    167.94.145.21      40,616   \n",
      "\n",
      "        destination.ip destination.port source.geo.country_name  \\\n",
      "17747          8.8.8.8               53                       -   \n",
      "8445   192.168.245.254           18,234                 Uruguay   \n",
      "20364    200.125.11.37            4,719         The Netherlands   \n",
      "18416   200.40.211.237              443                 Uruguay   \n",
      "9619    200.40.211.238           17,778           United States   \n",
      "\n",
      "                         source.as.organization.name  \\\n",
      "17747                                              -   \n",
      "8445   Administracion Nacional de Telecomunicaciones   \n",
      "20364                                   Alsycon B.V.   \n",
      "18416  Administracion Nacional de Telecomunicaciones   \n",
      "9619                                  CENSYS-ARIN-02   \n",
      "\n",
      "      destination.geo.country_name network.application destination.nat.ip  \\\n",
      "17747                United States          domain-udp                  -   \n",
      "8445                             -         tunnel_test                  -   \n",
      "20364                      Uruguay      tcp-high-ports                  -   \n",
      "18416                      Uruguay               https                  -   \n",
      "9619                       Uruguay      tcp-high-ports                  -   \n",
      "\n",
      "                event.type network.transport checkpoint.rule_action  \\\n",
      "17747  allowed, connection               udp                 Accept   \n",
      "8445   allowed, connection               udp                 Accept   \n",
      "20364   connection, denied               tcp                   Drop   \n",
      "18416  allowed, connection               tcp                 Accept   \n",
      "9619    connection, denied               tcp                   Drop   \n",
      "\n",
      "      network.direction  \n",
      "17747           inbound  \n",
      "8445           outbound  \n",
      "20364           inbound  \n",
      "18416           inbound  \n",
      "9619            inbound  \n"
     ]
    }
   ],
   "source": [
    "\"\"\" df.drop(df.columns[0], axis=1, inplace=True) \"\"\"\n",
    "print(df)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 319,
     "status": "ok",
     "timestamp": 1708823870142,
     "user": {
      "displayName": "Dario Perla",
      "userId": "14261311295065514135"
     },
     "user_tz": 180
    },
    "id": "kduVQDBwwMRr",
    "outputId": "a6bb8ee6-4c07-4899-fc2a-58a6c75bf83f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 16328 entries, 2247 to 12644\n",
      "Data columns (total 14 columns):\n",
      " #   Column                        Non-Null Count  Dtype \n",
      "---  ------                        --------------  ----- \n",
      " 0   event.created                 16328 non-null  object\n",
      " 1   source.ip                     16328 non-null  object\n",
      " 2   source.port                   16328 non-null  object\n",
      " 3   destination.ip                16328 non-null  object\n",
      " 4   destination.port              16328 non-null  object\n",
      " 5   source.geo.country_name       16328 non-null  object\n",
      " 6   source.as.organization.name   16328 non-null  object\n",
      " 7   destination.geo.country_name  16328 non-null  object\n",
      " 8   network.application           16328 non-null  object\n",
      " 9   destination.nat.ip            16328 non-null  object\n",
      " 10  event.type                    16328 non-null  object\n",
      " 11  network.transport             16328 non-null  object\n",
      " 12  checkpoint.rule_action        16328 non-null  object\n",
      " 13  network.direction             16328 non-null  object\n",
      "dtypes: object(14)\n",
      "memory usage: 1.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 321,
     "status": "ok",
     "timestamp": 1708823875464,
     "user": {
      "displayName": "Dario Perla",
      "userId": "14261311295065514135"
     },
     "user_tz": 180
    },
    "id": "3q6d0h-dwarq",
    "outputId": "88aa4cc0-8b5b-431a-b254-61eeded12025"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 'event.created' contains non-numeric values.\n",
      "Column 'source.ip' contains non-numeric values.\n",
      "Column 'source.port' contains non-numeric values.\n",
      "Column 'destination.ip' contains non-numeric values.\n",
      "Column 'destination.port' contains non-numeric values.\n",
      "Column 'source.geo.country_name' contains non-numeric values.\n",
      "Column 'source.as.organization.name' contains non-numeric values.\n",
      "Column 'destination.geo.country_name' contains non-numeric values.\n",
      "Column 'network.application' contains non-numeric values.\n",
      "Column 'destination.nat.ip' contains non-numeric values.\n",
      "Column 'event.type' contains non-numeric values.\n",
      "Column 'network.transport' contains non-numeric values.\n",
      "Column 'checkpoint.rule_action' contains non-numeric values.\n",
      "Column 'network.direction' contains non-numeric values.\n"
     ]
    }
   ],
   "source": [
    "for col in df.columns:\n",
    "    try:\n",
    "        df[col].astype(float)\n",
    "    except ValueError:\n",
    "        print(f\"Column '{col}' contains non-numeric values.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 301,
     "status": "ok",
     "timestamp": 1708824241214,
     "user": {
      "displayName": "Dario Perla",
      "userId": "14261311295065514135"
     },
     "user_tz": 180
    },
    "id": "VyZHHUinwl01",
    "outputId": "8900b43a-abbd-4357-99b8-0227688a4604"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17747    Accept\n",
      "8445     Accept\n",
      "20364      Drop\n",
      "18416    Accept\n",
      "9619       Drop\n",
      "Name: checkpoint.rule_action, dtype: object\n"
     ]
    }
   ],
   "source": [
    "non_numeric_column = \"checkpoint.rule_action\"  # Replace with the actual column name\n",
    "print(df[non_numeric_column].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7BM2Q8e6yjhl"
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 6)\n",
    "pd.set_option('display.max_rows', 5)\n",
    "\n",
    "df = process_dataframe(df)\n",
    "df.dropna(inplace=True, axis=1)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HPKc9duszDqY",
    "outputId": "332a98a2-2cf7-487e-df8f-fcab1e5f90fc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-13901c134c89>:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_attack.dropna(inplace=True, axis=1)\n"
     ]
    }
   ],
   "source": [
    "normal_mask = df['checkpoint.rule_action']=='Accept'\n",
    "attack_mask = df['checkpoint.rule_action']!='Drop'\n",
    "\n",
    "df.drop('checkpoint.rule_action',axis=1,inplace=True)\n",
    "\n",
    "df_normal = df[normal_mask]\n",
    "df_attack = df[attack_mask]\n",
    "df_normal = process_dataframe(df_attack)\n",
    "df_normal.dropna(inplace=True, axis=1)\n",
    "df_attack.dropna(inplace=True, axis=1)\n",
    "df_attack = process_dataframe(df_normal)\n",
    "\n",
    "\n",
    "print(df.head())\n",
    "\n",
    "print(f\"Normal count: {len(df_normal)}\")\n",
    "print(f\"Attack count: {len(df_attack)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7vdrfl9g0Jag"
   },
   "outputs": [],
   "source": [
    "# This is the numeric feature vector, as it goes to the neural net\n",
    "x_normal = df_normal.values\n",
    "x_attack = df_attack.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pnpoq1Vi0UT-"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_normal_train, x_normal_test = train_test_split(\n",
    "    x_normal, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9272,
     "status": "ok",
     "timestamp": 1708823542537,
     "user": {
      "displayName": "Dario Perla",
      "userId": "14261311295065514135"
     },
     "user_tz": 180
    },
    "id": "kb-C5H-U0ZtR",
    "outputId": "addabcd6-313c-44e3-daa8-cc578bd05967"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.015089166516970311\n",
      "Epoch [2/10], Loss: 0.0017625625727565161\n",
      "Epoch [3/10], Loss: 0.0011732291958261548\n",
      "Epoch [4/10], Loss: 0.001122224926283317\n",
      "Epoch [5/10], Loss: 0.0011104200322214247\n",
      "Epoch [6/10], Loss: 0.0011081521203907738\n",
      "Epoch [7/10], Loss: 0.0011082047442739298\n",
      "Epoch [8/10], Loss: 0.0011075983680452087\n",
      "Epoch [9/10], Loss: 0.0011081941400854184\n",
      "Epoch [10/10], Loss: 0.0011082928270168071\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Convert numpy arrays to PyTorch tensors and move them to the appropriate device\n",
    "x_normal_train_tensor = torch.tensor(x_normal_train).float().to(device)\n",
    "x_normal_tensor = torch.tensor(x_normal).float().to(device)\n",
    "x_attack_tensor = torch.tensor(x_attack).float().to(device)\n",
    "\n",
    "# Create DataLoader for batch processing\n",
    "train_data = TensorDataset(x_normal_train_tensor, x_normal_train_tensor)\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "\n",
    "# Define the model using Sequential\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(x_normal.shape[1], 25),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(25, 3),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(3, 25),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(25, x_normal.shape[1])\n",
    ").to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 10\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0\n",
    "    den = 0\n",
    "    for data in train_loader:\n",
    "        inputs, targets = data\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss +=loss.item()\n",
    "        den+=1\n",
    "\n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {running_loss/den}')\n",
    "    running_loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1708823558272,
     "user": {
      "displayName": "Dario Perla",
      "userId": "14261311295065514135"
     },
     "user_tz": 180
    },
    "id": "4-Co7QmC0iwr",
    "outputId": "c626cd30-1019-42e5-94f9-173a2a42b1d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal train count: 1779\n",
      "Normal test count: 593\n"
     ]
    }
   ],
   "source": [
    "print(f\"Normal train count: {len(x_normal_train)}\")\n",
    "print(f\"Normal test count: {len(x_normal_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1485,
     "status": "ok",
     "timestamp": 1708823608516,
     "user": {
      "displayName": "Dario Perla",
      "userId": "14261311295065514135"
     },
     "user_tz": 180
    },
    "id": "qxQdKiRf0t3a",
    "outputId": "22b9a463-6f65-4bdd-a65d-0119a1d4d1fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out of Sample Normal Score (RMSE): 0.033687397837638855\n",
      "Insample Normal Score (RMSE): 0.033377647399902344\n",
      "Attack Underway Score (RMSE): 0.03433653712272644\n"
     ]
    }
   ],
   "source": [
    "model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "# Function to calculate RMSE\n",
    "def calculate_rmse(model, data):\n",
    "    with torch.no_grad():\n",
    "        predictions = model(data)\n",
    "        mse_loss = nn.MSELoss()(predictions, data)\n",
    "    return torch.sqrt(mse_loss).item()\n",
    "\n",
    "# Evaluating the model\n",
    "score1 = calculate_rmse(model, torch.tensor(x_normal_test).float().to(device))\n",
    "score2 = calculate_rmse(model, x_normal_tensor)\n",
    "score3 = calculate_rmse(model, x_attack_tensor)\n",
    "\n",
    "print(f\"Out of Sample Normal Score (RMSE): {score1}\")\n",
    "print(f\"Insample Normal Score (RMSE): {score2}\")\n",
    "print(f\"Attack Underway Score (RMSE): {score3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jzNlTCK3Mvyb"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9Zfz78fKMwMp"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
